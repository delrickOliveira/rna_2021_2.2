{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais Artificiais 2021.1\n",
    "\n",
    "- **Disciplina**: Redes Neurais Artificiais 2021.1  \n",
    "- **Professora**: Elloá B. Guedes (ebgcosta@uea.edu.br)  \n",
    "- **Github**: http://github.com/elloa  \n",
    "        \n",
    "\n",
    "Levando em conta a base de dados **_Forest Cover Type_**, esta parte do Projeto Prático diz respeito à proposição e avaliação de múltiplas redes neurais artificiais do tipo feedforward multilayer perceptron para o problema da classificação multi-classe da cobertura florestal em uma área do Roosevelt National Forest.\n",
    "\n",
    "## Busca em Grade\n",
    "\n",
    "Uma maneira padrão de escolher os parâmetros de um modelo de Machine Learning é por meio de uma busca em grade via força bruta. O algoritmo da busca em grade é dado como segue:\n",
    "\n",
    "1. Escolha a métrica de desempenho que você deseja maximizar  \n",
    "2. Escolha o algoritmo de Machine Learning (exemplo: redes neurais artificiais). Em seguida, defina os parâmetros ou hiperparâmetros deste tipo de modelo sobre os quais você dseja otimizar (número de épocas, taxa de aprendizado, etc.) e construa um array de valores a serem testados para cada parâmetro ou hiperparâmetro.  \n",
    "3. Defina a grade de busca, a qual é dada como o produto cartesiano de cada parâmetro a ser testado. Por exemplo, para os arrays [50, 100, 1000] e [10, 15], tem-se que a grade é [(50,10), (50,15), (100,10), (100,15), (1000,10), (1000,15)].\n",
    "4. Para cada combinação de parâmetros a serem otimizados, utilize o conjunto de treinamento para realizar uma validação cruzada (holdout ou k-fold) e calcule a métrica de avaliação no conjunto de teste (ou conjuntos de teste)\n",
    "5. Escolha a combinação de parâmetros que maximizam a métrica de avaliação. Este é o modelo otimizado.\n",
    "\n",
    "Por que esta abordagem funciona? Porque a busca em grade efetua uma pesquisa extensiva sobre as possíveis combinações de valores para cada um dos parâmetros a serem ajustados. Para cada combinação, ela estima a performance do modelo em dados novos. Por fim, o modelo com melhor métrica de desempenho é escolhido. Tem-se então que este modelo é o que melhor pode vir a generalizar mediante dados nunca antes vistos.\n",
    "\n",
    "## Efetuando a Busca em Grade sobre Hiperparâmetros das Top-6 RNAs\n",
    "\n",
    "Considerando a etapa anterior do projeto prático, foram identificadas pelo menos 6 melhores Redes Neurais para o problema da classificação multi-classe da cobertura florestal no conjunto de dados selecionado. Algumas destas redes possuem atributos categóricos como variáveis preditoras, enquanto outras possuem apenas os atributos numéricos como preditores.\n",
    "\n",
    "A primeira etapa desta segunda parte do projeto consiste em trazer para este notebook estas seis arquiteturas, ressaltando:\n",
    "\n",
    "1. Número de neurônios ocultos por camada  \n",
    "2. Função de Ativação  \n",
    "3. Utilização ou não de atributos categóricos   \n",
    "4. Desempenho médio +- desvio padrão nos testes anteriores  \n",
    "5. Número de repetições que a equipe conseguiu realizar para verificar os resultados  \n",
    "\n",
    "Elabore uma busca em grade sobre estas arquiteturas que contemple variações nos hiperparâmetros a seguir, conforme documentação de [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n",
    "\n",
    "A. Solver  (Não usar o LBFGS, pois é mais adequado para datasets pequenos)  \n",
    "B. Batch Size  \n",
    "C. Learning Rate Init  \n",
    "D. Paciência (n_iter_no_change)  \n",
    "E. Épocas  \n",
    "\n",
    "Nesta busca em grande, contemple a utilização do objeto [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação Cruzada k-fold\n",
    "\n",
    "Na elaboração da busca em grid, vamos avaliar os modelos propostos segundo uma estratégia de validação cruzada ainda não explorada até o momento: a validação cruzada k-fold. Segundo a mesma, o conjunto de dados é particionado em k partes: a cada iteração, separa-se uma das partes para teste e o modelo é treinado com as k-1 partes remanescentes. Valores sugestivos de k na literatura são k = 3, 5 ou 10, pois o custo computacional desta validação dos modelos é alto. A métrica de desempenho é resultante da média dos desempenhos nas k iterações. A figura a seguir ilustra a ideia desta avaliação\n",
    "\n",
    "<img src = \"https://ethen8181.github.io/machine-learning/model_selection/img/kfolds.png\" width=600></img>\n",
    "\n",
    "Considerando a métrica de desempenho F1-Score, considere a validação cruzada 5-fold para aferir os resultados da busca em grande anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificando a mellhor solução\n",
    "\n",
    "Como resultado da busca em grande com validação cruzada 5-fold, identifique o modelo otimizado com melhor desempenho para o problema. Apresente claramente este modelo, seus parâmetros, hiperparâmetros otimizados e resultados para cada um dos folds avaliados. Esta é a melhor solução identificada em decorrência deste projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empacotando a solução\n",
    "\n",
    "Suponha que você deve entregar este classificador ao órgão responsável por administrar o Roosevelt National Park. Para tanto, você deve fazer uma preparação do mesmo para utilização neste cenário. Uma vez que já identificou os melhores parâmetros e hiperparâmetros, o passo remanescente consiste em treinar o modelo com estes valores e todos os dados disponíveis, salvando o conjunto de pesos do modelo ao final para entrega ao cliente. Assim, finalize o projeto prático realizando tais passos.\n",
    "\n",
    "1. Consulte a documentação a seguir:\n",
    "https://scikit-learn.org/stable/modules/model_persistence.html  \n",
    "2. Treine o modelo com todos os dados  \n",
    "3. Salve o modelo em disco  \n",
    "4. Construa uma rotina que recupere o modelo em disco  \n",
    "5. Mostre que a rotina é funcional, fazendo previsões com todos os elementos do dataset e exibindo uma matriz de confusão das mesmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score,accuracy_score,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import math as mt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca em Grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os 2 TOPs 3 Sem Atributos Categóricos - 15 Iterações em Cada Modelo <p>\n",
    "    <img src = \"https://github.com/delrickOliveira/rna_2021_2.2/blob/main/img/Imagem1-SAT.png?raw=true\"></img> <p>\n",
    "    <img src = \"https://github.com/delrickOliveira/rna_2021_2.2/blob/main/img/Imagem2-SAT.png?raw=true\"></img> <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('covtype.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :(data.shape[1] - 1)]\n",
    "y = data.iloc[:, -1:]\n",
    "X = np.array(data.drop('Cover_Type', axis = 1))\n",
    "Y = np.array(data.Cover_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "X_test_std = (X_test - np.mean(X_train))/np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Solver  (Não usar o LBFGS, pois é mais adequado para datasets pequenos)  \n",
    "B. Batch Size - o número de exemplos de treinamento em uma passagem para frente / para trás. Quanto maior o tamanho do lote, mais espaço de memória você precisará. <p>\n",
    "C. Learning Rate Init  \n",
    "D. Paciência (n_iter_no_change)  \n",
    "E. Épocas  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'solver':['sgd','adam'],\n",
    "              'batch_size':['auto',1000],\n",
    "              'learning_rate_init':[0.001,0.005],\n",
    "              'n_iter_no_change':[5,10],\n",
    "              'max_iter':[300,500],\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diminuímos bastante os diferentes parâmetros a serem testados na Base, pois acabava totalizando mais de 1500 Treinamentos, algo inviável no momento dos nossos testes.\n",
    "\n",
    "\n",
    "Tentamos usar Um Batch_size muito pequeno (1) e o tempo de execução aumentou consideravelmente;<p>\n",
    "Ao usar uma Paciência muito alta(150+), o algoritmo entrou praticamente em loop infinito, não sendo viável utilizar valores altos nesse caso.<p>\n",
    "Outro parâmetro removido, foi o número máximo de épocas em 100, pois na grande maioria dos treinos estava resultando em ultrapassar este limite sem convergir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid = GridSearchCV(estimator = clf,          \n",
    "                    param_grid = parameters,  # É aquele dicionário com valores para serem testados.\n",
    "                    n_jobs=-1, #Number of jobs to run in parallel. \n",
    "                    cv=5,#Validação Cruzada com 5 Folds\n",
    "                    verbose=4)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPClassifier(), n_jobs=-1,\n",
       "             param_grid={'batch_size': ['auto', 1000],\n",
       "                         'learning_rate_init': [0.001, 0.005],\n",
       "                         'max_iter': [300, 500], 'n_iter_no_change': [5, 10],\n",
       "                         'solver': ['sgd', 'adam']},\n",
       "             verbose=4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o grid.\n",
    "grid.fit(X_train_std, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report\n",
    "mlp = MLPClassifier(random_state=1,hidden_layer_sizes = (12,), max_iter=300,activation = 'relu', solver = 'sgd',verbose=False)\n",
    "mlp.fit(X_train_std, y_train)\n",
    "prediction=mlp.predict(X_train_std)\n",
    "print(classification_report(y_train, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_n_iter_no_change</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1134.521022</td>\n",
       "      <td>91.516619</td>\n",
       "      <td>0.284310</td>\n",
       "      <td>0.030292</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.740183</td>\n",
       "      <td>0.735991</td>\n",
       "      <td>0.742851</td>\n",
       "      <td>0.738582</td>\n",
       "      <td>0.730947</td>\n",
       "      <td>0.737711</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2203.192770</td>\n",
       "      <td>447.950923</td>\n",
       "      <td>2.277592</td>\n",
       "      <td>0.288956</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.758304</td>\n",
       "      <td>0.756731</td>\n",
       "      <td>0.767881</td>\n",
       "      <td>0.767227</td>\n",
       "      <td>0.759383</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077.383217</td>\n",
       "      <td>20.415507</td>\n",
       "      <td>0.287431</td>\n",
       "      <td>0.036437</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.746084</td>\n",
       "      <td>0.738868</td>\n",
       "      <td>0.739516</td>\n",
       "      <td>0.741447</td>\n",
       "      <td>0.742319</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4158.049740</td>\n",
       "      <td>464.471018</td>\n",
       "      <td>2.552527</td>\n",
       "      <td>0.359983</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.768262</td>\n",
       "      <td>0.764181</td>\n",
       "      <td>0.767181</td>\n",
       "      <td>0.768481</td>\n",
       "      <td>0.758117</td>\n",
       "      <td>0.765244</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1801.278014</td>\n",
       "      <td>84.358742</td>\n",
       "      <td>0.315552</td>\n",
       "      <td>0.045705</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.749920</td>\n",
       "      <td>0.748002</td>\n",
       "      <td>0.749932</td>\n",
       "      <td>0.749905</td>\n",
       "      <td>0.744065</td>\n",
       "      <td>0.748365</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2446.353651</td>\n",
       "      <td>320.495750</td>\n",
       "      <td>2.355699</td>\n",
       "      <td>0.297775</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.764267</td>\n",
       "      <td>0.763701</td>\n",
       "      <td>0.764955</td>\n",
       "      <td>0.766551</td>\n",
       "      <td>0.763490</td>\n",
       "      <td>0.764593</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1816.072544</td>\n",
       "      <td>49.077156</td>\n",
       "      <td>0.278061</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.754026</td>\n",
       "      <td>0.745617</td>\n",
       "      <td>0.746035</td>\n",
       "      <td>0.748712</td>\n",
       "      <td>0.746954</td>\n",
       "      <td>0.748269</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3451.540844</td>\n",
       "      <td>538.506729</td>\n",
       "      <td>2.264090</td>\n",
       "      <td>0.153525</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.769566</td>\n",
       "      <td>0.770365</td>\n",
       "      <td>0.765656</td>\n",
       "      <td>0.759875</td>\n",
       "      <td>0.771099</td>\n",
       "      <td>0.767312</td>\n",
       "      <td>0.004166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>694.103356</td>\n",
       "      <td>115.211659</td>\n",
       "      <td>0.268686</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.754961</td>\n",
       "      <td>0.756928</td>\n",
       "      <td>0.754002</td>\n",
       "      <td>0.745540</td>\n",
       "      <td>0.751257</td>\n",
       "      <td>0.752537</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1996.415222</td>\n",
       "      <td>379.651300</td>\n",
       "      <td>4.505196</td>\n",
       "      <td>0.341477</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.751617</td>\n",
       "      <td>0.750879</td>\n",
       "      <td>0.755022</td>\n",
       "      <td>0.736787</td>\n",
       "      <td>0.732054</td>\n",
       "      <td>0.745272</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1083.556009</td>\n",
       "      <td>47.478760</td>\n",
       "      <td>0.281185</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.748383</td>\n",
       "      <td>0.755354</td>\n",
       "      <td>0.757112</td>\n",
       "      <td>0.750679</td>\n",
       "      <td>0.756875</td>\n",
       "      <td>0.753681</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3041.591721</td>\n",
       "      <td>772.114615</td>\n",
       "      <td>4.249005</td>\n",
       "      <td>0.643479</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.764636</td>\n",
       "      <td>0.760099</td>\n",
       "      <td>0.742519</td>\n",
       "      <td>0.759654</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.755589</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>690.047797</td>\n",
       "      <td>85.343480</td>\n",
       "      <td>0.278059</td>\n",
       "      <td>0.011689</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.754370</td>\n",
       "      <td>0.750609</td>\n",
       "      <td>0.747658</td>\n",
       "      <td>0.737623</td>\n",
       "      <td>0.743684</td>\n",
       "      <td>0.746789</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1894.369456</td>\n",
       "      <td>391.628668</td>\n",
       "      <td>4.280250</td>\n",
       "      <td>0.276812</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.751371</td>\n",
       "      <td>0.750818</td>\n",
       "      <td>0.756546</td>\n",
       "      <td>0.756765</td>\n",
       "      <td>0.758486</td>\n",
       "      <td>0.754797</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1372.810014</td>\n",
       "      <td>65.606881</td>\n",
       "      <td>0.318676</td>\n",
       "      <td>0.053752</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.763480</td>\n",
       "      <td>0.751985</td>\n",
       "      <td>0.733336</td>\n",
       "      <td>0.752155</td>\n",
       "      <td>0.761805</td>\n",
       "      <td>0.752552</td>\n",
       "      <td>0.010722</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2840.615666</td>\n",
       "      <td>943.756436</td>\n",
       "      <td>4.380225</td>\n",
       "      <td>0.879836</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.746970</td>\n",
       "      <td>0.755944</td>\n",
       "      <td>0.758882</td>\n",
       "      <td>0.751466</td>\n",
       "      <td>0.751958</td>\n",
       "      <td>0.753044</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>739.421810</td>\n",
       "      <td>48.542218</td>\n",
       "      <td>0.243693</td>\n",
       "      <td>0.015931</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.719419</td>\n",
       "      <td>0.717108</td>\n",
       "      <td>0.718718</td>\n",
       "      <td>0.718764</td>\n",
       "      <td>0.716908</td>\n",
       "      <td>0.718184</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>896.675398</td>\n",
       "      <td>291.502470</td>\n",
       "      <td>1.380927</td>\n",
       "      <td>0.665594</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.753018</td>\n",
       "      <td>0.764734</td>\n",
       "      <td>0.759472</td>\n",
       "      <td>0.760367</td>\n",
       "      <td>0.754466</td>\n",
       "      <td>0.758411</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>839.998916</td>\n",
       "      <td>37.607710</td>\n",
       "      <td>0.309302</td>\n",
       "      <td>0.018219</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.721337</td>\n",
       "      <td>0.717366</td>\n",
       "      <td>0.718645</td>\n",
       "      <td>0.718986</td>\n",
       "      <td>0.719145</td>\n",
       "      <td>0.719096</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1293.021092</td>\n",
       "      <td>98.785275</td>\n",
       "      <td>1.687103</td>\n",
       "      <td>0.275748</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.755698</td>\n",
       "      <td>0.767574</td>\n",
       "      <td>0.757736</td>\n",
       "      <td>0.761707</td>\n",
       "      <td>0.761790</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1382.708757</td>\n",
       "      <td>97.611238</td>\n",
       "      <td>0.324925</td>\n",
       "      <td>0.041213</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.728947</td>\n",
       "      <td>0.725849</td>\n",
       "      <td>0.725615</td>\n",
       "      <td>0.727776</td>\n",
       "      <td>0.725772</td>\n",
       "      <td>0.726792</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>705.088552</td>\n",
       "      <td>215.887964</td>\n",
       "      <td>0.956843</td>\n",
       "      <td>0.604132</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.752428</td>\n",
       "      <td>0.761673</td>\n",
       "      <td>0.754125</td>\n",
       "      <td>0.764854</td>\n",
       "      <td>0.759273</td>\n",
       "      <td>0.758470</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1473.466940</td>\n",
       "      <td>76.700342</td>\n",
       "      <td>0.296807</td>\n",
       "      <td>0.009879</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.723722</td>\n",
       "      <td>0.727533</td>\n",
       "      <td>0.729488</td>\n",
       "      <td>0.724702</td>\n",
       "      <td>0.727395</td>\n",
       "      <td>0.726568</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1882.600784</td>\n",
       "      <td>627.603932</td>\n",
       "      <td>1.865187</td>\n",
       "      <td>0.480834</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.758759</td>\n",
       "      <td>0.760554</td>\n",
       "      <td>0.760616</td>\n",
       "      <td>0.765629</td>\n",
       "      <td>0.767878</td>\n",
       "      <td>0.762687</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>529.550427</td>\n",
       "      <td>77.788965</td>\n",
       "      <td>0.296804</td>\n",
       "      <td>0.063262</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.740503</td>\n",
       "      <td>0.731160</td>\n",
       "      <td>0.724263</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.716773</td>\n",
       "      <td>0.729762</td>\n",
       "      <td>0.008445</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>586.061418</td>\n",
       "      <td>258.614393</td>\n",
       "      <td>2.115947</td>\n",
       "      <td>0.675425</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.761243</td>\n",
       "      <td>0.748433</td>\n",
       "      <td>0.748002</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.752511</td>\n",
       "      <td>0.752626</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>858.133445</td>\n",
       "      <td>88.317529</td>\n",
       "      <td>0.290556</td>\n",
       "      <td>0.023380</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.727705</td>\n",
       "      <td>0.736102</td>\n",
       "      <td>0.716272</td>\n",
       "      <td>0.736578</td>\n",
       "      <td>0.727960</td>\n",
       "      <td>0.728923</td>\n",
       "      <td>0.007384</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1895.399935</td>\n",
       "      <td>401.520784</td>\n",
       "      <td>3.764742</td>\n",
       "      <td>0.492804</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.763714</td>\n",
       "      <td>0.763345</td>\n",
       "      <td>0.747511</td>\n",
       "      <td>0.748208</td>\n",
       "      <td>0.753851</td>\n",
       "      <td>0.755326</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>463.927302</td>\n",
       "      <td>54.329376</td>\n",
       "      <td>0.309303</td>\n",
       "      <td>0.058781</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.732561</td>\n",
       "      <td>0.723525</td>\n",
       "      <td>0.730803</td>\n",
       "      <td>0.710023</td>\n",
       "      <td>0.728513</td>\n",
       "      <td>0.725085</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>548.852795</td>\n",
       "      <td>341.496715</td>\n",
       "      <td>2.044395</td>\n",
       "      <td>0.935031</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.749969</td>\n",
       "      <td>0.748494</td>\n",
       "      <td>0.752576</td>\n",
       "      <td>0.733898</td>\n",
       "      <td>0.734906</td>\n",
       "      <td>0.743969</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1074.297828</td>\n",
       "      <td>248.903841</td>\n",
       "      <td>0.301609</td>\n",
       "      <td>0.025737</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.733987</td>\n",
       "      <td>0.741474</td>\n",
       "      <td>0.732291</td>\n",
       "      <td>0.737918</td>\n",
       "      <td>0.744655</td>\n",
       "      <td>0.738065</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1838.329992</td>\n",
       "      <td>295.340132</td>\n",
       "      <td>3.370150</td>\n",
       "      <td>0.884383</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.746306</td>\n",
       "      <td>0.727718</td>\n",
       "      <td>0.748605</td>\n",
       "      <td>0.756212</td>\n",
       "      <td>0.755621</td>\n",
       "      <td>0.746892</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     1134.521022     91.516619         0.284310        0.030292   \n",
       "1     2203.192770    447.950923         2.277592        0.288956   \n",
       "2     1077.383217     20.415507         0.287431        0.036437   \n",
       "3     4158.049740    464.471018         2.552527        0.359983   \n",
       "4     1801.278014     84.358742         0.315552        0.045705   \n",
       "5     2446.353651    320.495750         2.355699        0.297775   \n",
       "6     1816.072544     49.077156         0.278061        0.020725   \n",
       "7     3451.540844    538.506729         2.264090        0.153525   \n",
       "8      694.103356    115.211659         0.268686        0.011690   \n",
       "9     1996.415222    379.651300         4.505196        0.341477   \n",
       "10    1083.556009     47.478760         0.281185        0.009880   \n",
       "11    3041.591721    772.114615         4.249005        0.643479   \n",
       "12     690.047797     85.343480         0.278059        0.011689   \n",
       "13    1894.369456    391.628668         4.280250        0.276812   \n",
       "14    1372.810014     65.606881         0.318676        0.053752   \n",
       "15    2840.615666    943.756436         4.380225        0.879836   \n",
       "16     739.421810     48.542218         0.243693        0.015931   \n",
       "17     896.675398    291.502470         1.380927        0.665594   \n",
       "18     839.998916     37.607710         0.309302        0.018219   \n",
       "19    1293.021092     98.785275         1.687103        0.275748   \n",
       "20    1382.708757     97.611238         0.324925        0.041213   \n",
       "21     705.088552    215.887964         0.956843        0.604132   \n",
       "22    1473.466940     76.700342         0.296807        0.009879   \n",
       "23    1882.600784    627.603932         1.865187        0.480834   \n",
       "24     529.550427     77.788965         0.296804        0.063262   \n",
       "25     586.061418    258.614393         2.115947        0.675425   \n",
       "26     858.133445     88.317529         0.290556        0.023380   \n",
       "27    1895.399935    401.520784         3.764742        0.492804   \n",
       "28     463.927302     54.329376         0.309303        0.058781   \n",
       "29     548.852795    341.496715         2.044395        0.935031   \n",
       "30    1074.297828    248.903841         0.301609        0.025737   \n",
       "31    1838.329992    295.340132         3.370150        0.884383   \n",
       "\n",
       "   param_batch_size param_learning_rate_init param_max_iter  \\\n",
       "0              auto                    0.001            300   \n",
       "1              auto                    0.001            300   \n",
       "2              auto                    0.001            300   \n",
       "3              auto                    0.001            300   \n",
       "4              auto                    0.001            500   \n",
       "5              auto                    0.001            500   \n",
       "6              auto                    0.001            500   \n",
       "7              auto                    0.001            500   \n",
       "8              auto                    0.005            300   \n",
       "9              auto                    0.005            300   \n",
       "10             auto                    0.005            300   \n",
       "11             auto                    0.005            300   \n",
       "12             auto                    0.005            500   \n",
       "13             auto                    0.005            500   \n",
       "14             auto                    0.005            500   \n",
       "15             auto                    0.005            500   \n",
       "16             1000                    0.001            300   \n",
       "17             1000                    0.001            300   \n",
       "18             1000                    0.001            300   \n",
       "19             1000                    0.001            300   \n",
       "20             1000                    0.001            500   \n",
       "21             1000                    0.001            500   \n",
       "22             1000                    0.001            500   \n",
       "23             1000                    0.001            500   \n",
       "24             1000                    0.005            300   \n",
       "25             1000                    0.005            300   \n",
       "26             1000                    0.005            300   \n",
       "27             1000                    0.005            300   \n",
       "28             1000                    0.005            500   \n",
       "29             1000                    0.005            500   \n",
       "30             1000                    0.005            500   \n",
       "31             1000                    0.005            500   \n",
       "\n",
       "   param_n_iter_no_change param_solver  \\\n",
       "0                       5          sgd   \n",
       "1                       5         adam   \n",
       "2                      10          sgd   \n",
       "3                      10         adam   \n",
       "4                       5          sgd   \n",
       "5                       5         adam   \n",
       "6                      10          sgd   \n",
       "7                      10         adam   \n",
       "8                       5          sgd   \n",
       "9                       5         adam   \n",
       "10                     10          sgd   \n",
       "11                     10         adam   \n",
       "12                      5          sgd   \n",
       "13                      5         adam   \n",
       "14                     10          sgd   \n",
       "15                     10         adam   \n",
       "16                      5          sgd   \n",
       "17                      5         adam   \n",
       "18                     10          sgd   \n",
       "19                     10         adam   \n",
       "20                      5          sgd   \n",
       "21                      5         adam   \n",
       "22                     10          sgd   \n",
       "23                     10         adam   \n",
       "24                      5          sgd   \n",
       "25                      5         adam   \n",
       "26                     10          sgd   \n",
       "27                     10         adam   \n",
       "28                      5          sgd   \n",
       "29                      5         adam   \n",
       "30                     10          sgd   \n",
       "31                     10         adam   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'batch_size': 'auto', 'learning_rate_init': 0...           0.740183   \n",
       "1   {'batch_size': 'auto', 'learning_rate_init': 0...           0.758304   \n",
       "2   {'batch_size': 'auto', 'learning_rate_init': 0...           0.745679   \n",
       "3   {'batch_size': 'auto', 'learning_rate_init': 0...           0.768262   \n",
       "4   {'batch_size': 'auto', 'learning_rate_init': 0...           0.749920   \n",
       "5   {'batch_size': 'auto', 'learning_rate_init': 0...           0.764267   \n",
       "6   {'batch_size': 'auto', 'learning_rate_init': 0...           0.754026   \n",
       "7   {'batch_size': 'auto', 'learning_rate_init': 0...           0.769566   \n",
       "8   {'batch_size': 'auto', 'learning_rate_init': 0...           0.754961   \n",
       "9   {'batch_size': 'auto', 'learning_rate_init': 0...           0.751617   \n",
       "10  {'batch_size': 'auto', 'learning_rate_init': 0...           0.748383   \n",
       "11  {'batch_size': 'auto', 'learning_rate_init': 0...           0.764636   \n",
       "12  {'batch_size': 'auto', 'learning_rate_init': 0...           0.754370   \n",
       "13  {'batch_size': 'auto', 'learning_rate_init': 0...           0.751371   \n",
       "14  {'batch_size': 'auto', 'learning_rate_init': 0...           0.763480   \n",
       "15  {'batch_size': 'auto', 'learning_rate_init': 0...           0.746970   \n",
       "16  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.719419   \n",
       "17  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.753018   \n",
       "18  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.721337   \n",
       "19  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.766234   \n",
       "20  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.728947   \n",
       "21  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.752428   \n",
       "22  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.723722   \n",
       "23  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.758759   \n",
       "24  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.740503   \n",
       "25  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.761243   \n",
       "26  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.727705   \n",
       "27  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.763714   \n",
       "28  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.732561   \n",
       "29  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.749969   \n",
       "30  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.733987   \n",
       "31  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.746306   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.735991           0.742851           0.738582   \n",
       "1            0.756731           0.767881           0.767227   \n",
       "2            0.746084           0.738868           0.739516   \n",
       "3            0.764181           0.767181           0.768481   \n",
       "4            0.748002           0.749932           0.749905   \n",
       "5            0.763701           0.764955           0.766551   \n",
       "6            0.745617           0.746035           0.748712   \n",
       "7            0.770365           0.765656           0.759875   \n",
       "8            0.756928           0.754002           0.745540   \n",
       "9            0.750879           0.755022           0.736787   \n",
       "10           0.755354           0.757112           0.750679   \n",
       "11           0.760099           0.742519           0.759654   \n",
       "12           0.750609           0.747658           0.737623   \n",
       "13           0.750818           0.756546           0.756765   \n",
       "14           0.751985           0.733336           0.752155   \n",
       "15           0.755944           0.758882           0.751466   \n",
       "16           0.717108           0.718718           0.718764   \n",
       "17           0.764734           0.759472           0.760367   \n",
       "18           0.717366           0.718645           0.718986   \n",
       "19           0.755698           0.767574           0.757736   \n",
       "20           0.725849           0.725615           0.727776   \n",
       "21           0.761673           0.754125           0.764854   \n",
       "22           0.727533           0.729488           0.724702   \n",
       "23           0.760554           0.760616           0.765629   \n",
       "24           0.731160           0.724263           0.736111   \n",
       "25           0.748433           0.748002           0.752941   \n",
       "26           0.736102           0.716272           0.736578   \n",
       "27           0.763345           0.747511           0.748208   \n",
       "28           0.723525           0.730803           0.710023   \n",
       "29           0.748494           0.752576           0.733898   \n",
       "30           0.741474           0.732291           0.737918   \n",
       "31           0.727718           0.748605           0.756212   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.730947         0.737711        0.004050               25  \n",
       "1            0.759383         0.761905        0.004693                5  \n",
       "2            0.741447         0.742319        0.003033               23  \n",
       "3            0.758117         0.765244        0.003880                2  \n",
       "4            0.744065         0.748365        0.002274               17  \n",
       "5            0.763490         0.764593        0.001103                3  \n",
       "6            0.746954         0.748269        0.003069               18  \n",
       "7            0.771099         0.767312        0.004166                1  \n",
       "8            0.751257         0.752537        0.003947               16  \n",
       "9            0.732054         0.745272        0.009094               21  \n",
       "10           0.756875         0.753681        0.003517               12  \n",
       "11           0.751036         0.755589        0.007877                9  \n",
       "12           0.743684         0.746789        0.005770               20  \n",
       "13           0.758486         0.754797        0.003102               11  \n",
       "14           0.761805         0.752552        0.010722               15  \n",
       "15           0.751958         0.753044        0.004076               13  \n",
       "16           0.716908         0.718184        0.000993               32  \n",
       "17           0.754466         0.758411        0.004233                8  \n",
       "18           0.719145         0.719096        0.001283               31  \n",
       "19           0.761707         0.761790        0.004621                6  \n",
       "20           0.725772         0.726792        0.001336               28  \n",
       "21           0.759273         0.758470        0.004627                7  \n",
       "22           0.727395         0.726568        0.002084               29  \n",
       "23           0.767878         0.762687        0.003460                4  \n",
       "24           0.716773         0.729762        0.008445               26  \n",
       "25           0.752511         0.752626        0.004761               14  \n",
       "26           0.727960         0.728923        0.007384               27  \n",
       "27           0.753851         0.755326        0.007051               10  \n",
       "28           0.728513         0.725085        0.008120               30  \n",
       "29           0.734906         0.743969        0.007926               22  \n",
       "30           0.744655         0.738065        0.004584               24  \n",
       "31           0.755621         0.746892        0.010334               19  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimindo os resultados.\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'batch_size': 'auto', 'learning_rate_init': 0.001, 'max_iter': 500, 'n_iter_no_change': 10, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters found:\\n', grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_grid = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_n_iter_no_change</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3451.540844</td>\n",
       "      <td>538.506729</td>\n",
       "      <td>2.264090</td>\n",
       "      <td>0.153525</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.769566</td>\n",
       "      <td>0.770365</td>\n",
       "      <td>0.765656</td>\n",
       "      <td>0.759875</td>\n",
       "      <td>0.771099</td>\n",
       "      <td>0.767312</td>\n",
       "      <td>0.004166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4158.049740</td>\n",
       "      <td>464.471018</td>\n",
       "      <td>2.552527</td>\n",
       "      <td>0.359983</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.768262</td>\n",
       "      <td>0.764181</td>\n",
       "      <td>0.767181</td>\n",
       "      <td>0.768481</td>\n",
       "      <td>0.758117</td>\n",
       "      <td>0.765244</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2446.353651</td>\n",
       "      <td>320.495750</td>\n",
       "      <td>2.355699</td>\n",
       "      <td>0.297775</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.764267</td>\n",
       "      <td>0.763701</td>\n",
       "      <td>0.764955</td>\n",
       "      <td>0.766551</td>\n",
       "      <td>0.763490</td>\n",
       "      <td>0.764593</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1882.600784</td>\n",
       "      <td>627.603932</td>\n",
       "      <td>1.865187</td>\n",
       "      <td>0.480834</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.758759</td>\n",
       "      <td>0.760554</td>\n",
       "      <td>0.760616</td>\n",
       "      <td>0.765629</td>\n",
       "      <td>0.767878</td>\n",
       "      <td>0.762687</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2203.192770</td>\n",
       "      <td>447.950923</td>\n",
       "      <td>2.277592</td>\n",
       "      <td>0.288956</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.758304</td>\n",
       "      <td>0.756731</td>\n",
       "      <td>0.767881</td>\n",
       "      <td>0.767227</td>\n",
       "      <td>0.759383</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1293.021092</td>\n",
       "      <td>98.785275</td>\n",
       "      <td>1.687103</td>\n",
       "      <td>0.275748</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.755698</td>\n",
       "      <td>0.767574</td>\n",
       "      <td>0.757736</td>\n",
       "      <td>0.761707</td>\n",
       "      <td>0.761790</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>705.088552</td>\n",
       "      <td>215.887964</td>\n",
       "      <td>0.956843</td>\n",
       "      <td>0.604132</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.752428</td>\n",
       "      <td>0.761673</td>\n",
       "      <td>0.754125</td>\n",
       "      <td>0.764854</td>\n",
       "      <td>0.759273</td>\n",
       "      <td>0.758470</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>896.675398</td>\n",
       "      <td>291.502470</td>\n",
       "      <td>1.380927</td>\n",
       "      <td>0.665594</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.753018</td>\n",
       "      <td>0.764734</td>\n",
       "      <td>0.759472</td>\n",
       "      <td>0.760367</td>\n",
       "      <td>0.754466</td>\n",
       "      <td>0.758411</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3041.591721</td>\n",
       "      <td>772.114615</td>\n",
       "      <td>4.249005</td>\n",
       "      <td>0.643479</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.764636</td>\n",
       "      <td>0.760099</td>\n",
       "      <td>0.742519</td>\n",
       "      <td>0.759654</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.755589</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1895.399935</td>\n",
       "      <td>401.520784</td>\n",
       "      <td>3.764742</td>\n",
       "      <td>0.492804</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.763714</td>\n",
       "      <td>0.763345</td>\n",
       "      <td>0.747511</td>\n",
       "      <td>0.748208</td>\n",
       "      <td>0.753851</td>\n",
       "      <td>0.755326</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1894.369456</td>\n",
       "      <td>391.628668</td>\n",
       "      <td>4.280250</td>\n",
       "      <td>0.276812</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.751371</td>\n",
       "      <td>0.750818</td>\n",
       "      <td>0.756546</td>\n",
       "      <td>0.756765</td>\n",
       "      <td>0.758486</td>\n",
       "      <td>0.754797</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1083.556009</td>\n",
       "      <td>47.478760</td>\n",
       "      <td>0.281185</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.748383</td>\n",
       "      <td>0.755354</td>\n",
       "      <td>0.757112</td>\n",
       "      <td>0.750679</td>\n",
       "      <td>0.756875</td>\n",
       "      <td>0.753681</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2840.615666</td>\n",
       "      <td>943.756436</td>\n",
       "      <td>4.380225</td>\n",
       "      <td>0.879836</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.746970</td>\n",
       "      <td>0.755944</td>\n",
       "      <td>0.758882</td>\n",
       "      <td>0.751466</td>\n",
       "      <td>0.751958</td>\n",
       "      <td>0.753044</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>586.061418</td>\n",
       "      <td>258.614393</td>\n",
       "      <td>2.115947</td>\n",
       "      <td>0.675425</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.761243</td>\n",
       "      <td>0.748433</td>\n",
       "      <td>0.748002</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.752511</td>\n",
       "      <td>0.752626</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1372.810014</td>\n",
       "      <td>65.606881</td>\n",
       "      <td>0.318676</td>\n",
       "      <td>0.053752</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.763480</td>\n",
       "      <td>0.751985</td>\n",
       "      <td>0.733336</td>\n",
       "      <td>0.752155</td>\n",
       "      <td>0.761805</td>\n",
       "      <td>0.752552</td>\n",
       "      <td>0.010722</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>694.103356</td>\n",
       "      <td>115.211659</td>\n",
       "      <td>0.268686</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.754961</td>\n",
       "      <td>0.756928</td>\n",
       "      <td>0.754002</td>\n",
       "      <td>0.745540</td>\n",
       "      <td>0.751257</td>\n",
       "      <td>0.752537</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1801.278014</td>\n",
       "      <td>84.358742</td>\n",
       "      <td>0.315552</td>\n",
       "      <td>0.045705</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.749920</td>\n",
       "      <td>0.748002</td>\n",
       "      <td>0.749932</td>\n",
       "      <td>0.749905</td>\n",
       "      <td>0.744065</td>\n",
       "      <td>0.748365</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1816.072544</td>\n",
       "      <td>49.077156</td>\n",
       "      <td>0.278061</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.754026</td>\n",
       "      <td>0.745617</td>\n",
       "      <td>0.746035</td>\n",
       "      <td>0.748712</td>\n",
       "      <td>0.746954</td>\n",
       "      <td>0.748269</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1838.329992</td>\n",
       "      <td>295.340132</td>\n",
       "      <td>3.370150</td>\n",
       "      <td>0.884383</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.746306</td>\n",
       "      <td>0.727718</td>\n",
       "      <td>0.748605</td>\n",
       "      <td>0.756212</td>\n",
       "      <td>0.755621</td>\n",
       "      <td>0.746892</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>690.047797</td>\n",
       "      <td>85.343480</td>\n",
       "      <td>0.278059</td>\n",
       "      <td>0.011689</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.754370</td>\n",
       "      <td>0.750609</td>\n",
       "      <td>0.747658</td>\n",
       "      <td>0.737623</td>\n",
       "      <td>0.743684</td>\n",
       "      <td>0.746789</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1996.415222</td>\n",
       "      <td>379.651300</td>\n",
       "      <td>4.505196</td>\n",
       "      <td>0.341477</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.751617</td>\n",
       "      <td>0.750879</td>\n",
       "      <td>0.755022</td>\n",
       "      <td>0.736787</td>\n",
       "      <td>0.732054</td>\n",
       "      <td>0.745272</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>548.852795</td>\n",
       "      <td>341.496715</td>\n",
       "      <td>2.044395</td>\n",
       "      <td>0.935031</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.749969</td>\n",
       "      <td>0.748494</td>\n",
       "      <td>0.752576</td>\n",
       "      <td>0.733898</td>\n",
       "      <td>0.734906</td>\n",
       "      <td>0.743969</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077.383217</td>\n",
       "      <td>20.415507</td>\n",
       "      <td>0.287431</td>\n",
       "      <td>0.036437</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.746084</td>\n",
       "      <td>0.738868</td>\n",
       "      <td>0.739516</td>\n",
       "      <td>0.741447</td>\n",
       "      <td>0.742319</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1074.297828</td>\n",
       "      <td>248.903841</td>\n",
       "      <td>0.301609</td>\n",
       "      <td>0.025737</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.733987</td>\n",
       "      <td>0.741474</td>\n",
       "      <td>0.732291</td>\n",
       "      <td>0.737918</td>\n",
       "      <td>0.744655</td>\n",
       "      <td>0.738065</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1134.521022</td>\n",
       "      <td>91.516619</td>\n",
       "      <td>0.284310</td>\n",
       "      <td>0.030292</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 'auto', 'learning_rate_init': 0...</td>\n",
       "      <td>0.740183</td>\n",
       "      <td>0.735991</td>\n",
       "      <td>0.742851</td>\n",
       "      <td>0.738582</td>\n",
       "      <td>0.730947</td>\n",
       "      <td>0.737711</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>529.550427</td>\n",
       "      <td>77.788965</td>\n",
       "      <td>0.296804</td>\n",
       "      <td>0.063262</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.740503</td>\n",
       "      <td>0.731160</td>\n",
       "      <td>0.724263</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.716773</td>\n",
       "      <td>0.729762</td>\n",
       "      <td>0.008445</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>858.133445</td>\n",
       "      <td>88.317529</td>\n",
       "      <td>0.290556</td>\n",
       "      <td>0.023380</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.727705</td>\n",
       "      <td>0.736102</td>\n",
       "      <td>0.716272</td>\n",
       "      <td>0.736578</td>\n",
       "      <td>0.727960</td>\n",
       "      <td>0.728923</td>\n",
       "      <td>0.007384</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1382.708757</td>\n",
       "      <td>97.611238</td>\n",
       "      <td>0.324925</td>\n",
       "      <td>0.041213</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.728947</td>\n",
       "      <td>0.725849</td>\n",
       "      <td>0.725615</td>\n",
       "      <td>0.727776</td>\n",
       "      <td>0.725772</td>\n",
       "      <td>0.726792</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1473.466940</td>\n",
       "      <td>76.700342</td>\n",
       "      <td>0.296807</td>\n",
       "      <td>0.009879</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.723722</td>\n",
       "      <td>0.727533</td>\n",
       "      <td>0.729488</td>\n",
       "      <td>0.724702</td>\n",
       "      <td>0.727395</td>\n",
       "      <td>0.726568</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>463.927302</td>\n",
       "      <td>54.329376</td>\n",
       "      <td>0.309303</td>\n",
       "      <td>0.058781</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.732561</td>\n",
       "      <td>0.723525</td>\n",
       "      <td>0.730803</td>\n",
       "      <td>0.710023</td>\n",
       "      <td>0.728513</td>\n",
       "      <td>0.725085</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>839.998916</td>\n",
       "      <td>37.607710</td>\n",
       "      <td>0.309302</td>\n",
       "      <td>0.018219</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.721337</td>\n",
       "      <td>0.717366</td>\n",
       "      <td>0.718645</td>\n",
       "      <td>0.718986</td>\n",
       "      <td>0.719145</td>\n",
       "      <td>0.719096</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>739.421810</td>\n",
       "      <td>48.542218</td>\n",
       "      <td>0.243693</td>\n",
       "      <td>0.015931</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1000, 'learning_rate_init': 0.0...</td>\n",
       "      <td>0.719419</td>\n",
       "      <td>0.717108</td>\n",
       "      <td>0.718718</td>\n",
       "      <td>0.718764</td>\n",
       "      <td>0.716908</td>\n",
       "      <td>0.718184</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7     3451.540844    538.506729         2.264090        0.153525   \n",
       "3     4158.049740    464.471018         2.552527        0.359983   \n",
       "5     2446.353651    320.495750         2.355699        0.297775   \n",
       "23    1882.600784    627.603932         1.865187        0.480834   \n",
       "1     2203.192770    447.950923         2.277592        0.288956   \n",
       "19    1293.021092     98.785275         1.687103        0.275748   \n",
       "21     705.088552    215.887964         0.956843        0.604132   \n",
       "17     896.675398    291.502470         1.380927        0.665594   \n",
       "11    3041.591721    772.114615         4.249005        0.643479   \n",
       "27    1895.399935    401.520784         3.764742        0.492804   \n",
       "13    1894.369456    391.628668         4.280250        0.276812   \n",
       "10    1083.556009     47.478760         0.281185        0.009880   \n",
       "15    2840.615666    943.756436         4.380225        0.879836   \n",
       "25     586.061418    258.614393         2.115947        0.675425   \n",
       "14    1372.810014     65.606881         0.318676        0.053752   \n",
       "8      694.103356    115.211659         0.268686        0.011690   \n",
       "4     1801.278014     84.358742         0.315552        0.045705   \n",
       "6     1816.072544     49.077156         0.278061        0.020725   \n",
       "31    1838.329992    295.340132         3.370150        0.884383   \n",
       "12     690.047797     85.343480         0.278059        0.011689   \n",
       "9     1996.415222    379.651300         4.505196        0.341477   \n",
       "29     548.852795    341.496715         2.044395        0.935031   \n",
       "2     1077.383217     20.415507         0.287431        0.036437   \n",
       "30    1074.297828    248.903841         0.301609        0.025737   \n",
       "0     1134.521022     91.516619         0.284310        0.030292   \n",
       "24     529.550427     77.788965         0.296804        0.063262   \n",
       "26     858.133445     88.317529         0.290556        0.023380   \n",
       "20    1382.708757     97.611238         0.324925        0.041213   \n",
       "22    1473.466940     76.700342         0.296807        0.009879   \n",
       "28     463.927302     54.329376         0.309303        0.058781   \n",
       "18     839.998916     37.607710         0.309302        0.018219   \n",
       "16     739.421810     48.542218         0.243693        0.015931   \n",
       "\n",
       "   param_batch_size param_learning_rate_init param_max_iter  \\\n",
       "7              auto                    0.001            500   \n",
       "3              auto                    0.001            300   \n",
       "5              auto                    0.001            500   \n",
       "23             1000                    0.001            500   \n",
       "1              auto                    0.001            300   \n",
       "19             1000                    0.001            300   \n",
       "21             1000                    0.001            500   \n",
       "17             1000                    0.001            300   \n",
       "11             auto                    0.005            300   \n",
       "27             1000                    0.005            300   \n",
       "13             auto                    0.005            500   \n",
       "10             auto                    0.005            300   \n",
       "15             auto                    0.005            500   \n",
       "25             1000                    0.005            300   \n",
       "14             auto                    0.005            500   \n",
       "8              auto                    0.005            300   \n",
       "4              auto                    0.001            500   \n",
       "6              auto                    0.001            500   \n",
       "31             1000                    0.005            500   \n",
       "12             auto                    0.005            500   \n",
       "9              auto                    0.005            300   \n",
       "29             1000                    0.005            500   \n",
       "2              auto                    0.001            300   \n",
       "30             1000                    0.005            500   \n",
       "0              auto                    0.001            300   \n",
       "24             1000                    0.005            300   \n",
       "26             1000                    0.005            300   \n",
       "20             1000                    0.001            500   \n",
       "22             1000                    0.001            500   \n",
       "28             1000                    0.005            500   \n",
       "18             1000                    0.001            300   \n",
       "16             1000                    0.001            300   \n",
       "\n",
       "   param_n_iter_no_change param_solver  \\\n",
       "7                      10         adam   \n",
       "3                      10         adam   \n",
       "5                       5         adam   \n",
       "23                     10         adam   \n",
       "1                       5         adam   \n",
       "19                     10         adam   \n",
       "21                      5         adam   \n",
       "17                      5         adam   \n",
       "11                     10         adam   \n",
       "27                     10         adam   \n",
       "13                      5         adam   \n",
       "10                     10          sgd   \n",
       "15                     10         adam   \n",
       "25                      5         adam   \n",
       "14                     10          sgd   \n",
       "8                       5          sgd   \n",
       "4                       5          sgd   \n",
       "6                      10          sgd   \n",
       "31                     10         adam   \n",
       "12                      5          sgd   \n",
       "9                       5         adam   \n",
       "29                      5         adam   \n",
       "2                      10          sgd   \n",
       "30                     10          sgd   \n",
       "0                       5          sgd   \n",
       "24                      5          sgd   \n",
       "26                     10          sgd   \n",
       "20                      5          sgd   \n",
       "22                     10          sgd   \n",
       "28                      5          sgd   \n",
       "18                     10          sgd   \n",
       "16                      5          sgd   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "7   {'batch_size': 'auto', 'learning_rate_init': 0...           0.769566   \n",
       "3   {'batch_size': 'auto', 'learning_rate_init': 0...           0.768262   \n",
       "5   {'batch_size': 'auto', 'learning_rate_init': 0...           0.764267   \n",
       "23  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.758759   \n",
       "1   {'batch_size': 'auto', 'learning_rate_init': 0...           0.758304   \n",
       "19  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.766234   \n",
       "21  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.752428   \n",
       "17  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.753018   \n",
       "11  {'batch_size': 'auto', 'learning_rate_init': 0...           0.764636   \n",
       "27  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.763714   \n",
       "13  {'batch_size': 'auto', 'learning_rate_init': 0...           0.751371   \n",
       "10  {'batch_size': 'auto', 'learning_rate_init': 0...           0.748383   \n",
       "15  {'batch_size': 'auto', 'learning_rate_init': 0...           0.746970   \n",
       "25  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.761243   \n",
       "14  {'batch_size': 'auto', 'learning_rate_init': 0...           0.763480   \n",
       "8   {'batch_size': 'auto', 'learning_rate_init': 0...           0.754961   \n",
       "4   {'batch_size': 'auto', 'learning_rate_init': 0...           0.749920   \n",
       "6   {'batch_size': 'auto', 'learning_rate_init': 0...           0.754026   \n",
       "31  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.746306   \n",
       "12  {'batch_size': 'auto', 'learning_rate_init': 0...           0.754370   \n",
       "9   {'batch_size': 'auto', 'learning_rate_init': 0...           0.751617   \n",
       "29  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.749969   \n",
       "2   {'batch_size': 'auto', 'learning_rate_init': 0...           0.745679   \n",
       "30  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.733987   \n",
       "0   {'batch_size': 'auto', 'learning_rate_init': 0...           0.740183   \n",
       "24  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.740503   \n",
       "26  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.727705   \n",
       "20  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.728947   \n",
       "22  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.723722   \n",
       "28  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.732561   \n",
       "18  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.721337   \n",
       "16  {'batch_size': 1000, 'learning_rate_init': 0.0...           0.719419   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7            0.770365           0.765656           0.759875   \n",
       "3            0.764181           0.767181           0.768481   \n",
       "5            0.763701           0.764955           0.766551   \n",
       "23           0.760554           0.760616           0.765629   \n",
       "1            0.756731           0.767881           0.767227   \n",
       "19           0.755698           0.767574           0.757736   \n",
       "21           0.761673           0.754125           0.764854   \n",
       "17           0.764734           0.759472           0.760367   \n",
       "11           0.760099           0.742519           0.759654   \n",
       "27           0.763345           0.747511           0.748208   \n",
       "13           0.750818           0.756546           0.756765   \n",
       "10           0.755354           0.757112           0.750679   \n",
       "15           0.755944           0.758882           0.751466   \n",
       "25           0.748433           0.748002           0.752941   \n",
       "14           0.751985           0.733336           0.752155   \n",
       "8            0.756928           0.754002           0.745540   \n",
       "4            0.748002           0.749932           0.749905   \n",
       "6            0.745617           0.746035           0.748712   \n",
       "31           0.727718           0.748605           0.756212   \n",
       "12           0.750609           0.747658           0.737623   \n",
       "9            0.750879           0.755022           0.736787   \n",
       "29           0.748494           0.752576           0.733898   \n",
       "2            0.746084           0.738868           0.739516   \n",
       "30           0.741474           0.732291           0.737918   \n",
       "0            0.735991           0.742851           0.738582   \n",
       "24           0.731160           0.724263           0.736111   \n",
       "26           0.736102           0.716272           0.736578   \n",
       "20           0.725849           0.725615           0.727776   \n",
       "22           0.727533           0.729488           0.724702   \n",
       "28           0.723525           0.730803           0.710023   \n",
       "18           0.717366           0.718645           0.718986   \n",
       "16           0.717108           0.718718           0.718764   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7            0.771099         0.767312        0.004166                1  \n",
       "3            0.758117         0.765244        0.003880                2  \n",
       "5            0.763490         0.764593        0.001103                3  \n",
       "23           0.767878         0.762687        0.003460                4  \n",
       "1            0.759383         0.761905        0.004693                5  \n",
       "19           0.761707         0.761790        0.004621                6  \n",
       "21           0.759273         0.758470        0.004627                7  \n",
       "17           0.754466         0.758411        0.004233                8  \n",
       "11           0.751036         0.755589        0.007877                9  \n",
       "27           0.753851         0.755326        0.007051               10  \n",
       "13           0.758486         0.754797        0.003102               11  \n",
       "10           0.756875         0.753681        0.003517               12  \n",
       "15           0.751958         0.753044        0.004076               13  \n",
       "25           0.752511         0.752626        0.004761               14  \n",
       "14           0.761805         0.752552        0.010722               15  \n",
       "8            0.751257         0.752537        0.003947               16  \n",
       "4            0.744065         0.748365        0.002274               17  \n",
       "6            0.746954         0.748269        0.003069               18  \n",
       "31           0.755621         0.746892        0.010334               19  \n",
       "12           0.743684         0.746789        0.005770               20  \n",
       "9            0.732054         0.745272        0.009094               21  \n",
       "29           0.734906         0.743969        0.007926               22  \n",
       "2            0.741447         0.742319        0.003033               23  \n",
       "30           0.744655         0.738065        0.004584               24  \n",
       "0            0.730947         0.737711        0.004050               25  \n",
       "24           0.716773         0.729762        0.008445               26  \n",
       "26           0.727960         0.728923        0.007384               27  \n",
       "20           0.725772         0.726792        0.001336               28  \n",
       "22           0.727395         0.726568        0.002084               29  \n",
       "28           0.728513         0.725085        0.008120               30  \n",
       "18           0.719145         0.719096        0.001283               31  \n",
       "16           0.716908         0.718184        0.000993               32  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_grid.sort_values(by=['rank_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = grid.predict(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.67      0.73    148339\n",
      "           2       0.75      0.89      0.81    198352\n",
      "           3       0.81      0.76      0.78     24989\n",
      "           4       0.89      0.64      0.75      1932\n",
      "           5       0.83      0.22      0.34      6606\n",
      "           6       0.64      0.60      0.62     12120\n",
      "           7       0.88      0.61      0.72     14370\n",
      "\n",
      "    accuracy                           0.77    406708\n",
      "   macro avg       0.80      0.63      0.68    406708\n",
      "weighted avg       0.78      0.77      0.76    406708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_train, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pickle\n",
    "\n",
    "filename = 'result_grid.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação utilizando os melhores Parâmetros e Salvando em disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('covtype.csv')\n",
    "\n",
    "X = data.iloc[:, :(data.shape[1] - 1)]\n",
    "y = data.iloc[:, -1:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7,shuffle = True)\n",
    "\n",
    "X_train_std = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "X_test_std = (X_test - np.mean(X_train))/np.std(X_train)\n",
    "\n",
    "clf = MLPClassifier(solver = 'adam',\n",
    "              batch_size = 'auto',\n",
    "              hidden_layer_sizes = (15,15),\n",
    "              learning_rate_init = 0.001,\n",
    "              n_iter_no_change = 10,\n",
    "              max_iter = 500,\n",
    ")\n",
    "\n",
    "clf.fit(X_train_std, y_train)\n",
    "import pickle\n",
    "\n",
    "filename = 'Roosevelt.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
